{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1obP63eJq2lbsr4EtYPZ6eXSxpAbWQKCG","authorship_tag":"ABX9TyMannnPuW8/zxHqlpQvxVIV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["결함 : 히든 레이어가 있나 없나 결과가 비슷함\n","\n","해결방법 : activation function - > 활성함수\n","\n","loss = 실제값 - |예측값|\n","\n","sigmoid - 0과 1사이\n","\n","hyperbolic tangent\n","-1 과 1사이\n","\n","recified linear unit\n","양수면 x 그대로, 음수면 0\n","이 활성함수 넣게 되면 layer가 유의미해짐\n","- 비선형적인 예측을 하기 위하여 활성함수 사용\n","\n","활성화함수 x => 선형적, 단순한 예측\n","\n"],"metadata":{"id":"q6vN-gzPyhT5"}},{"cell_type":"markdown","source":["loss값이 가장 적은 곳이 총손실E를 최소화 하는 곳\n","\n","첫w1는 랜덤 -> 변수가 여러개인 경우 대입이\n","어렵기 때문에 w1값을 최적값으로 변경하기 위해\n","경사 하강법을 사용\n","->\n","현재 w1값에서 접선의 기울기를 w1에서 빼셈\n","\n","*새로운 w1을 구하려면 w1값이 총손실에 얼마나 큰 영향을 미치는지 구하여 빼라\n","머신러닝 = 손실을 최소화하는 w값 찾게 시킴-> 경사 하강을 사용하여\n","\n","\n"," 1) w값들 랜덤으로 찍음\n","\n"," 2) w값 바탕으로 총손실 e를 계산함\n","\n"," 3) 경사하강으로 새로운 w값 업데이트\n","\n"," 4) w값 바탕으로 또 총 손실 반복 반복 반복\n","\n"," 5) loss가 줄어들지 않는 곳이 최적값\n"],"metadata":{"id":"ldmlS7Th5CHm"}},{"cell_type":"code","source":["#python 예시\n","'''w1 = 0.1 (랜덤)\n","w2 = 0.1 (랜덤)\n","\n","for i in 여러번반복:\n","  (1) w1이랑 w2로 예측값 y계산\n","  (2) 총손실 E계산 ( 예측값 - 실제값 등 )\n","  (3) w1 = 기존 w1 - ( w1이 E에 끼치는 영향(기울기) * learning rate )\n","  (4) w2 = 기존 w1 - ( w2이 E에 끼치는 영향(기울기) * learning rate )'''"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":90},"id":"pd0TiyWg6liC","executionInfo":{"status":"ok","timestamp":1698977036061,"user_tz":-540,"elapsed":15,"user":{"displayName":"고신형","userId":"05024536012020818867"}},"outputId":"db4d471f-76a3-45f5-f8a7-4213d7df2ee9"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'w1 = 0.1 (랜덤)\\nw2 = 0.1 (랜덤)\\n\\nfor i in 여러번반복:\\n  (1) w1이랑 w2로 예측값 y계산\\n  (2) 총손실 E계산 ( 예측값 - 실제값 등 )\\n  (3) w1 = 기존 w1 - ( w1이 E에 끼치는 영향(기울기) * learning rate )\\n  (4) w2 = 기존 w1 - ( w2이 E에 끼치는 영향(기울기) * learning rate )'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","source":["최저가 아니지만 기울기가 0이라 경사하강 멈추는 곳 존재\n","\n","방지하기 위해 learning rate 곱함\n","\n","- >  기울기 * learning rate를 곱하여 더 멀리가서 최저점을 찾는다\n","\n","learning rate에 고정값을 주면 학습이 느리거나 안늘어날 수 있음\n","\n"," - > learning rate optimizer\n","  - Momentum: 많이 뛰어넘으면 다음에도 많이 뛰어넘음\n","  - AdaGrad: 자주 변하는 w는 작게, 자주 안변하면 크게\n","  - RMSProp, AdaDelta, Adam 등등\n","\n","  - 보통은 Adam을 쓰면 된다\n","\n","몇십차원이 넘기때문에 기울기가 아닌 일명 편미분\n","\n","\n","\n"],"metadata":{"id":"B6uYGS2C7J82"}},{"cell_type":"markdown","source":["## W값 역전파 알고리즘으로 업데이트하는 법\n","###참고용\n","\n","ex) y두개 예측 해주삼\n","\n","w값 randomize\n","\n","w값 업데이트 순서는 마지막 레이러랑 가까운거 먼저\n","  \n","w3가 E에 미치는 영향\n","\n","-> z3/ w3 * a3/z3 * E/a3\n","\n","1) z3 = w3*a1 + w4 *a2 ==> a1만큼 영향\n","\n","2) a3 = sig(z3) * (1-sig(z3)"],"metadata":{"id":"xm1lWZTY8XYZ"}}]}